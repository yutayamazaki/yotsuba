#[cfg(test)]
mod tests {
    use yotsuba::ja::normalize;
    use yotsuba::utils::clean_emails;
    use yotsuba::utils::clean_emoji;
    use yotsuba::utils::clean_html_tags;
    use yotsuba::utils::clean_number;
    use yotsuba::utils::clean_url;
    use yotsuba::utils::get_stopwords;
    use yotsuba::utils::get_stopwords_by_frequency;
    use yotsuba::utils::pad_sequence;
    use yotsuba::utils::pad_sequence_post;
    use yotsuba::utils::pad_sequence_pre;
    use yotsuba::utils::pad_sequences;
    use yotsuba::utils::remove_stopwords;
    #[test]
    fn normalize_works() {
        // Test cases from: https://github.com/neologd/mecab-ipadic-neologd/wiki/Regexp.ja#python-written-by-hideaki-t--overlast
        let full_digits = "ÔºêÔºëÔºíÔºìÔºîÔºïÔºñÔºóÔºòÔºô";
        assert_eq!(normalize(full_digits), "0123456789");
        println!("{} -> {}", full_digits, normalize(full_digits));

        let full_large_alphabets = "Ôº°Ôº¢Ôº£Ôº§Ôº•Ôº¶ÔºßÔº®Ôº©Ôº™Ôº´Ôº¨Ôº≠ÔºÆÔºØÔº∞Ôº±Ôº≤Ôº≥Ôº¥ÔºµÔº∂Ôº∑Ôº∏ÔºπÔº∫";
        assert_eq!(
            normalize(full_large_alphabets),
            "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
        );
        println!(
            "{} -> {}",
            full_large_alphabets,
            normalize(full_large_alphabets)
        );

        let full_alphabets = "ÔΩÅÔΩÇÔΩÉÔΩÑÔΩÖÔΩÜÔΩáÔΩàÔΩâÔΩäÔΩãÔΩåÔΩçÔΩéÔΩèÔΩêÔΩëÔΩíÔΩìÔΩîÔΩïÔΩñÔΩóÔΩòÔΩôÔΩö";
        assert_eq!(normalize(full_alphabets), "abcdefghijklmnopqrstuvwxyz");
        println!("{} -> {}", full_alphabets, normalize(full_alphabets));

        // let full_symbols = "ÔºÅ‚ÄùÔºÉÔºÑÔºÖÔºÜ‚ÄôÔºàÔºâÔºäÔºãÔºåÔºçÔºéÔºèÔºöÔºõÔºúÔºûÔºüÔº†ÔºªÔø•ÔºΩÔºæÔºøÔΩÄÔΩõÔΩúÔΩù";
        // assert_eq!(normalize(full_symbols), "!\"#$%&'()*+,-./:;<>?@[¬•]^_`{|}");
        // println!("{} -> {}", full_symbols, normalize(full_symbols));

        let problem2 = "=ÔΩ°ÔΩ§ÔΩ•ÔΩ¢ÔΩ£";
        assert_eq!(normalize(problem2), "Ôºù„ÄÇ„ÄÅ„Éª„Äå„Äç");
        println!("{} -> {}", problem2, normalize(problem2));

        // assert "„Éè„É≥„Ç´„ÇØ" == normalize_neologd("ÔæäÔæùÔΩ∂ÔΩ∏")
        let problem3 = "ÔæäÔæùÔΩ∂ÔΩ∏";
        assert_eq!(normalize(problem3), "„Éè„É≥„Ç´„ÇØ");
        println!("{} -> {}", problem3, normalize(problem3));

        // assert "o-o" == normalize_neologd("o‚Ção")
        let problem4 = "o‚Ção";
        assert_eq!(normalize(problem4), "o-o");
        println!("{} -> {}", problem4, normalize(problem4));

        // assert "majika„Éº" == normalize_neologd("majika‚îÅ")
        let mut problem = "majika‚îÅ";
        assert_eq!(normalize(problem), "majika„Éº");
        println!("{} -> {}", problem, normalize(problem));

        // assert "„Çè„ÅÑ" == normalize_neologd("„Çè„Ä∞„ÅÑ")
        problem = "„Çè„Ä∞„ÅÑ";
        assert_eq!(normalize(problem), "„Çè„ÅÑ");
        println!("{} -> {}", problem, normalize(problem));

        // assert "„Çπ„Éº„Éë„Éº" == normalize_neologd("„Çπ„Éº„Éë„Éº„Éº„Éº„Éº")
        problem = "„Çπ„Éº„Éë„Éº„Éº„Éº„Éº";
        assert_eq!(normalize(problem), "„Çπ„Éº„Éë„Éº");
        println!("{} -> {}", problem, normalize(problem));

        // assert "!#" == normalize_neologd("!#")
        problem = "!#";
        assert_eq!(normalize(problem), "!#");
        println!("{} -> {}", problem, normalize(problem));

        // assert "„Çº„É≥„Ç´„ÇØ„Çπ„Éö„Éº„Çπ" == normalize_neologd("„Çº„É≥„Ç´„ÇØ„ÄÄ„Çπ„Éö„Éº„Çπ")
        problem = "„Çº„É≥„Ç´„ÇØ„ÄÄ„Çπ„Éö„Éº„Çπ";
        assert_eq!(normalize(problem), "„Çº„É≥„Ç´„ÇØ„Çπ„Éö„Éº„Çπ");
        println!("{} -> {}", problem, normalize(problem));

        // assert "„Åä„Åä" == normalize_neologd("„Åä             „Åä")
        problem = "„Åä             „Åä";
        assert_eq!(normalize(problem), "„Åä„Åä");
        println!("{} -> {}", problem, normalize(problem));

        // assert "„Åä„Åä" == normalize_neologd("      „Åä„Åä")
        problem = "      „Åä„Åä";
        assert_eq!(normalize(problem), "„Åä„Åä");
        println!("{} -> {}", problem, normalize(problem));

        // assert "„Åä„Åä" == normalize_neologd("„Åä„Åä      ")
        problem = "„Åä„Åä      ";
        assert_eq!(normalize(problem), "„Åä„Åä");
        println!("{} -> {}", problem, normalize(problem));

        // assert "Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥Ëá™‰ΩúÂÖ•ÈñÄ„ÇíË≤∑„ÅÑ„Åæ„Åó„Åü!!!" == normalize_neologd("Ê§úÁ¥¢ „Ç®„É≥„Ç∏„É≥ Ëá™‰Ωú ÂÖ•ÈñÄ „Çí Ë≤∑„ÅÑ „Åæ„Åó„Åü!!!")
        problem = "Ê§úÁ¥¢ „Ç®„É≥„Ç∏„É≥ Ëá™‰Ωú ÂÖ•ÈñÄ „Çí Ë≤∑„ÅÑ „Åæ„Åó„Åü!!!";
        assert_eq!(normalize(problem), "Ê§úÁ¥¢„Ç®„É≥„Ç∏„É≥Ëá™‰ΩúÂÖ•ÈñÄ„ÇíË≤∑„ÅÑ„Åæ„Åó„Åü!!!");
        println!("{} -> {}", problem, normalize(problem));

        // assert "„Ç¢„É´„Ç¥„É™„Ç∫„É†C" == normalize_neologd("„Ç¢„É´„Ç¥„É™„Ç∫„É† C")
        problem = "„Ç¢„É´„Ç¥„É™„Ç∫„É† C";
        assert_eq!(normalize(problem), "„Ç¢„É´„Ç¥„É™„Ç∫„É†C");
        println!("{} -> {}", problem, normalize(problem));

        // assert "PRMLÂâØË™≠Êú¨" == normalize_neologd("„ÄÄ„ÄÄ„ÄÄÔº∞Ôº≤Ôº≠Ôº¨„ÄÄ„ÄÄÂâØ„ÄÄË™≠„ÄÄÊú¨„ÄÄ„ÄÄ„ÄÄ")
        problem = "„ÄÄ„ÄÄ„ÄÄÔº∞Ôº≤Ôº≠Ôº¨„ÄÄ„ÄÄÂâØ„ÄÄË™≠„ÄÄÊú¨„ÄÄ„ÄÄ„ÄÄ";
        println!("{} -> {}", problem, normalize(problem));
        assert_eq!(normalize(problem), "PRMLÂâØË™≠Êú¨");

        // assert "Coding the Matrix" == normalize_neologd("Coding the Matrix")
        problem = "Coding the Matrix";
        assert_eq!(normalize(problem), "Coding the Matrix");
        println!("{} -> {}", problem, normalize(problem));

        // assert "Âçó„Ç¢„É´„Éó„Çπ„ÅÆÂ§©ÁÑ∂Ê∞¥Sparking Lemon„É¨„É¢„É≥‰∏ÄÁµû„Çä" == normalize_neologd("Âçó„Ç¢„É´„Éó„Çπ„ÅÆ„ÄÄÂ§©ÁÑ∂Ê∞¥„ÄÄÔº≥ÔΩêÔΩÅÔΩíÔΩãÔΩâÔΩéÔΩá„ÄÄÔº¨ÔΩÖÔΩçÔΩèÔΩé„ÄÄ„É¨„É¢„É≥‰∏ÄÁµû„Çä")
        problem = "Âçó„Ç¢„É´„Éó„Çπ„ÅÆ„ÄÄÂ§©ÁÑ∂Ê∞¥„ÄÄÔº≥ÔΩêÔΩÅÔΩíÔΩãÔΩâÔΩéÔΩá„ÄÄÔº¨ÔΩÖÔΩçÔΩèÔΩé„ÄÄ„É¨„É¢„É≥‰∏ÄÁµû„Çä";
        assert_eq!(
            normalize(problem),
            "Âçó„Ç¢„É´„Éó„Çπ„ÅÆÂ§©ÁÑ∂Ê∞¥Sparking Lemon„É¨„É¢„É≥‰∏ÄÁµû„Çä"
        );
        println!("{} -> {}", problem, normalize(problem));

        // problem = "Âçó„Ç¢„É´„Éó„Çπ„ÅÆ„ÄÄÂ§©ÁÑ∂Ê∞¥-„ÄÄÔº≥ÔΩêÔΩÅÔΩíÔΩãÔΩâÔΩéÔΩá*„ÄÄÔº¨ÔΩÖÔΩçÔΩèÔΩé+„ÄÄ„É¨„É¢„É≥‰∏ÄÁµû„Çä";
        // assert_eq!(
        //     normalize(problem),
        //     "Âçó„Ç¢„É´„Éó„Çπ„ÅÆÂ§©ÁÑ∂Ê∞¥-Sparking*Lemon+„É¨„É¢„É≥‰∏ÄÁµû„Çä"
        // );
        // println!("{} -> {}", problem, normalize(problem));
    }

    #[test]
    fn pad_sequences_works() {
        // Argument maxlen
        let sequences = vec![vec![1, 2, 3], vec![0, 2]];

        assert_eq!(
            pad_sequences(&sequences, Some(3), None, None).unwrap(),
            vec![vec![1, 2, 3], vec![0, 2, 0]]
        );
        assert_eq!(
            pad_sequences(&sequences, Some(4), None, None).unwrap(),
            vec![vec![1, 2, 3, 0], vec![0, 2, 0, 0]]
        );
        assert_eq!(
            pad_sequences(&sequences, None, None, None).unwrap(),
            pad_sequences(&sequences, Some(3), None, None).unwrap()
        );

        // Argument value
        assert_eq!(
            pad_sequences(&sequences, None, None, None).unwrap(),
            vec![vec![1, 2, 3], vec![0, 2, 0]]
        );
        assert_eq!(
            pad_sequences(&sequences, None, Some(1), None).unwrap(),
            vec![vec![1, 2, 3], vec![0, 2, 1]]
        );
        assert_eq!(
            pad_sequences(&sequences, None, Some(0), None).unwrap(),
            pad_sequences(&sequences, None, None, None).unwrap()
        );

        // Argument padding
        assert_eq!(
            pad_sequences(&sequences, None, None, None).unwrap(),
            pad_sequences(&sequences, None, None, Some("post")).unwrap()
        );
        assert_eq!(
            pad_sequences(&sequences, None, None, Some("pre")).unwrap(),
            vec![vec![1, 2, 3], vec![0, 0, 2]]
        );
    }

    #[test]
    fn clean_emoji_works() {
        let text = "üçÄyotsuba is a fast nlpü§ó toolkit implemented by Rust.";
        assert_eq!(
            clean_emoji(text, Some("")),
            "yotsuba is a fast nlp toolkit implemented by Rust."
        );
        assert_eq!(
            clean_emoji(text, Some("<EMOJI>")),
            "<EMOJI>yotsuba is a fast nlp<EMOJI> toolkit implemented by Rust."
        );
    }

    #[test]
    fn clean_url_works() {
        let text = "foohttp://localhost:8000 bar";
        assert_eq!(clean_url(text, Some("")), "foo bar");
        assert_eq!(clean_url(text, Some("<URL>")), "foo<URL> bar");
    }

    #[test]
    fn clean_html_tags_works() {
        let text = "foo<a>bar</a>.";
        assert_eq!(clean_html_tags(text, Some("")), "foobar.");
        assert_eq!(clean_html_tags(text, Some("<TAG>")), "foo<TAG>bar<TAG>.");
    }

    #[test]
    fn clean_emails_works() {
        let text1 = "Hello a@example.com.";
        assert_eq!(clean_emails(text1, None), "Hello .");
        assert_eq!(clean_emails(text1, Some("<EMAIL>")), "Hello <EMAIL>.");

        let text2 = "Hello a23@example2.com.";
        assert_eq!(clean_emails(text2, None), "Hello .");
    }

    #[test]
    fn clean_number_works() {
        let text = "I was born in 1912.02.04.";
        assert_eq!(clean_number(text, None), "I was born in 0.0.0.");
        assert_eq!(clean_number(text, Some("1")), "I was born in 1.1.1.");
    }

    #[test]
    fn pad_sequence_pre_works() {
        let sequence = vec![1, 2, 3];
        assert_eq!(pad_sequence_pre(&sequence, 5, None), vec![0, 0, 1, 2, 3]);
    }

    #[test]
    fn pad_sequence_pre_maxlen_smaller_than_seqlen() {
        let sequence = vec![1, 2, 3];
        assert_eq!(pad_sequence_pre(&sequence, 2, None), vec![1, 2]);
    }

    #[test]
    fn pad_sequence_post_works() {
        let sequence = vec![1, 2, 3];
        assert_eq!(
            pad_sequence_post(&sequence, 5, Some(5)),
            vec![1, 2, 3, 5, 5]
        );
    }

    #[test]
    fn pad_sequence_post_maxlen_smaller_than_seqlen() {
        let sequence = vec![1, 2, 3];
        assert_eq!(pad_sequence_post(&sequence, 2, None), vec![1, 2]);
    }

    #[test]
    fn pad_sequence_pre_and_post() {
        let sequence = vec![1, 2, 3];
        assert_eq!(
            pad_sequence(&sequence, 5, None, Some("pre")).unwrap(),
            vec![0, 0, 1, 2, 3]
        );
        assert_eq!(
            pad_sequence(&sequence, 5, None, Some("post")).unwrap(),
            vec![1, 2, 3, 0, 0]
        );
    }

    #[test]
    fn remove_stopwords_works() {
        let tokens = vec!["I", "am", "a", "dog"];
        let stopwords = vec!["am", "a"];
        let ret = remove_stopwords(&tokens, &stopwords);
        assert_eq!(ret, vec!["I", "dog"]);
    }

    #[test]
    fn get_stopwords_by_frequency_works() {
        let docs = vec![vec!["I", "am", "a", "dog"], vec!["I", "have", "a", "pen"]];
        let mut ret = get_stopwords_by_frequency(&docs, 2);
        ret.sort();
        assert_eq!(ret, vec!["I", "a"]);
    }

    #[test]
    fn get_stopwords_works() {
        let ret = get_stopwords("ja");
        assert_eq!(ret.unwrap().len(), 310);
    }
}
